{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_tys-e1RQFI"
      },
      "source": [
        "# Transformers in PyTorch\n",
        "\n",
        "Deep learning has made huge progress, especially in Natural Language Processing (NLP), thanks to transformer architectures. Although transformers became popular in NLP, their potential extends beyond text. They are gaining attention for time-series forecasting, which involves predicting future values based on past data—similar to how NLP models handle sequences of words. For example, forecasting stock prices or electricity usage is conceptually similar to translating one language to another. Both require understanding patterns and dependencies across sequences.\n",
        "\n",
        "This code lab explores how transformers can be adapted for time-series prediction using PyTorch.\n",
        "\n",
        "As is practice in this course, `XXXX` means you have to fill in the correct code. If you are following along and not in our course at the University of Rhode Island, you can find the answers in the `05-transformers-ANSWERKEY.ipynb` file in the repository.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Imports"
      ],
      "metadata": {
        "id": "2Kh8tBmb58Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "UzppyBnt2lXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "YzWSDxPcC8Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Create Synthetic Data\n",
        "\n",
        "We will generate a noisy sine wave to practice implementing a transformer for a regression task."
      ],
      "metadata": {
        "id": "XXaTqAmN5-Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic time series data\n",
        "time = np.arange(0, 1000, 0.1)\n",
        "amplitude = np.sin(time) + np.random.normal(0, 0.2, len(time))\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({'amplitude': amplitude})\n",
        "\n",
        "# Split the data\n",
        "train_size = int(len(df) * 0.8)\n",
        "df_train = df[:train_size]\n",
        "df_test = df[train_size:]"
      ],
      "metadata": {
        "id": "OzizynfO4xhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df_train['amplitude'], label='Training Data')\n",
        "plt.plot(df_test['amplitude'], label='Testing Data')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Synthetic Time Series Data')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cUIz65ge9nOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we've done for several other labs, we need to create many sequences from our larger dataset."
      ],
      "metadata": {
        "id": "uaawb57XbLxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence data preparation\n",
        "seq_length = 10\n",
        "\n",
        "def to_sequences(seq_size, data):\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(data) - seq_size - 1):\n",
        "        x.append(XXXX.tolist()) # Convert to list before appending\n",
        "        y.append(XXXX.item()) # Extract the scalar value before appending\n",
        "    return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, 1), torch.tensor(y, dtype=torch.float32).view(-1, 1)"
      ],
      "metadata": {
        "id": "80fWf3dr4u3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the 'amplitude' column as a NumPy array\n",
        "train_array = df_train['amplitude'].values\n",
        "test_array = df_test['amplitude'].values\n",
        "\n",
        "# Convert the NumPy array to a PyTorch tensor\n",
        "train_tensor = torch.tensor(train_array, dtype=torch.float32).view(-1, 1)\n",
        "test_tensor = torch.tensor(test_array, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Call the to_sequences function\n",
        "x_train, y_train = XXXX\n",
        "x_test, y_test = XXXX"
      ],
      "metadata": {
        "id": "WqeQGzB28Vmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now make our data into `TensorDatasets` and create `DataLoaders` for batch processing."
      ],
      "metadata": {
        "id": "jRlJZip7bUiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data loaders for batch\n",
        "train_dataset = TensorDataset(XXXX, XXXX)\n",
        "train_loader = DataLoader(XXXX)\n",
        "\n",
        "test_dataset = TensorDataset(XXXX, XXXX)\n",
        "test_loader = DataLoader(XXXX)"
      ],
      "metadata": {
        "id": "H0ffoo4W6RvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9TI-mjYTm9u"
      },
      "source": [
        "## Step 3: Position Encoding\n",
        "\n",
        "Transformers process all tokens at once rather than step-by-step like RNNs and LSTMs. This makes them faster but means they don’t naturally understand the order of tokens in a sequence. To fix this, we use positional encoding, which adds order information to token embeddings.\n",
        "\n",
        "Positional encodings are vectors added to token embeddings to help the model recognize positions in a sequence. A common way to generate them is with sinusoidal functions, which create unique patterns for each position.\n",
        "\n",
        "These functions help the model generalize to longer sequences it hasn’t seen before. Using simple position numbers instead wouldn’t work well because they might interfere with the trained embedding values.\n",
        "\n",
        "The `PositionalEncoding` class below helps provide information about the position of tokens in the input sequence. Let’s break down each part:\n",
        "\n",
        "* `__init__(self, d_model, dropout=0.1, max_len=5000)`: The constructor for the positional encoding layer.\n",
        "  * `d_model` is the size of the embedding dimension (i.e., the number of features for each token).\n",
        "  * `dropout` specifies the dropout rate to apply to the positional encodings for regularization.\n",
        "  * `max_len` is the maximum sequence length that the positional encoding will support.\n",
        "  * `self.dropout` = nn.Dropout(p=dropout): Creates a dropout layer that will be applied to the positional encodings to avoid overfitting. The dropout probability is controlled by `dropout`.\n",
        "* `pe = torch.zeros(max_len, d_model)`: Creates a tensor pe that will hold the positional encoding values. It is of shape `(max_len, d_model)` where `max_len` is the maximum sequence length, and `d_model` is the embedding dimension.\n",
        "* `position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)`: This line generates a tensor of shape `(max_len, 1)` representing the position of each token in the sequence. The `unsqueeze(1)` makes it a column vector, turning it into shape `(max_len, 1)` where each row represents the position of a token (e.g., 0, 1, 2, ..., max_len-1).\n",
        "* `div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))`: This creates a tensor that holds the scaling factors used for the positional encoding. The formula for the positional encoding involves applying a sine and cosine function with different frequencies for even and odd positions in the embedding space. This line computes the scaling factors for each dimension (`d_model`). The scaling is done exponentially, with the range of values chosen such that the frequencies vary smoothly across dimensions.\n",
        "* `pe[:, 0::2] = torch.sin(position * div_term)`: For even-indexed dimensions in the pe tensor (i.e., 0, 2, 4, ...), we assign the sine of the product of the position and the scaling factors `div_term`. This creates sinusoidal functions with different frequencies for different dimensions.\n",
        "* `pe[:, 1::2] = torch.cos(position * div_term)`: For odd-indexed dimensions (i.e., 1, 3, 5, ...), we assign the cosine of the same product. This gives alternating sine and cosine patterns for each position in the sequence.\n",
        "* `pe = pe.unsqueeze(0).transpose(0, 1)`: The `unsqueeze(0)` adds a batch dimension at the start, turning the shape from `(max_len, d_model)` to `(1, max_len, d_model)`. Then, the `transpose(0, 1)` swaps the batch and sequence dimensions, making the final shape `(max_len, 1, d_model)`. This is the expected shape for adding to the input sequence.\n",
        "* `self.register_buffer('pe', pe)`: This registers the positional encoding as a buffer, which means that it will be stored as part of the model’s state but won’t be considered a parameter (i.e., it won’t be updated during training). It is part of the model’s architecture and is used in the forward pass to add positional information.\n",
        "* `x = x + self.pe[:x.size(0), :]`: During the forward pass, the positional encoding is added to the input x. The positional encoding is sliced to match the sequence length of the input (x.size(0)) to ensure the correct dimensionality. This addition allows the model to incorporate the positional information into the token embeddings.\n",
        "* `return self.dropout(x)`: Finally, the result is passed through the dropout layer to apply regularization before returning the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi-bRiyCN7Cw"
      },
      "outputs": [],
      "source": [
        "# Positional Encoding for Transformer\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)  # tensor to hold position values\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # tensor for position of each token\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))  # scaling for functions\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # sin functions for even dimensions\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # cosine functions for odd dimensions\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)  # add batch dimensions and flip\n",
        "        self.register_buffer('pe', pe)  # store as part of model state but not a parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]  # add the position vector to the original\n",
        "        return self.dropout(x)  # add some dropout for regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJR-CJLeOzpd"
      },
      "source": [
        "## Step 4: Implementing a Transformer\n",
        "We will now implement a transformer model for time series forecasting using PyTorch. It will include:\n",
        "\n",
        "* An embedding layer to transform inputs to the right dimensions.\n",
        "* Positional encodings to preserve order information.\n",
        "* A transformer encoder to process the sequence.\n",
        "* An output layer to generate predictions.\n",
        "\n",
        "The three key parameters in a Transformer model—`d_model`, `nhead`, and `num_layers`—affect its performance, computational cost, and ability to generalize.\n",
        "\n",
        "  * **`d_model`**: This is the size of the input embeddings. A higher d_model allows the model to learn more complex patterns but increases computation and the risk of overfitting. Fortunately, normalization layers help manage these issues.\n",
        "\n",
        "  * **`nhead`**: This sets the number of attention heads in multi-head attention. More heads let the model focus on different parts of the input simultaneously, improving its ability to capture context. However, adding too many heads increases computational cost and may not always improve performance.\n",
        "\n",
        "  * **`num_layers`**: This controls the number of stacked Transformer encoder (or decoder) layers. More layers help the model learn deeper relationships in the data, but after a certain point, the benefits level off, and overfitting can become a problem. Training very deep models may require techniques like gradient clipping or learning rate adjustments.\n",
        "\n",
        "Choosing the right values for these parameters depends on the task, dataset, and available computing power. Finding the best settings often requires experimentation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoT-VFSdOANz"
      },
      "outputs": [],
      "source": [
        "# Model definition using Transformer\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2, dropout=0.2):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Linear(XXXX, XXXX)  # project into higher embedding space\n",
        "        self.pos_encoder = PositionalEncoding(XXXX, XXXX)  # add positional encoding\n",
        "        encoder_layers = nn.TransformerEncoderLayer(XXXX, XXXX)  # defining attention and FF network block\n",
        "        self.transformer_encoder = nn.TransformerEncoder(XXXX, XXXX)  # a stack of encoder blocks\n",
        "        self.output_layer = nn.Linear(XXXX, 1)  # make final predictions\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = XXXX\n",
        "        x = XXXX\n",
        "        x = XXXX\n",
        "        x = XXXX  # `(batch_size, seq_length, d_model)`, we take last sample\n",
        "        return x\n",
        "\n",
        "model = TransformerModel().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi_9wvWWfOGv"
      },
      "source": [
        "## Step 5: Training the Model\n",
        "\n",
        "Training a transformer-based model follows similar principles to other neural networks. Like other deep learning models, it benefits from batch training, which improves efficiency and helps generalization by updating weights based on multiple samples at once, rather than relying on single data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8-mF1OCOLnB"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        x_batch, y_batch = batch\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        XXXX\n",
        "        XXXX\n",
        "        XXXX\n",
        "        XXXX\n",
        "        XXXX\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS-lkHvOhXGm"
      },
      "source": [
        "## Step 6: Evaluate the Model\n",
        "\n",
        "We can now evaluate the performance of this model. We first need to set the model to eval and predict on our test data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "with XXXX:\n",
        "    for batch in test_loader:\n",
        "        x_batch, y_batch = batch\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        y_pred = XXXX\n",
        "        predictions.append(y_pred.cpu().numpy())\n",
        "        actuals.append(y_batch.cpu().numpy())\n",
        "\n",
        "# Flatten the lists into a single array\n",
        "predictions = np.concatenate(predictions)\n",
        "actuals = np.concatenate(actuals)"
      ],
      "metadata": {
        "id": "A1bfk9iCIFQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate some common metrics to quantify how close our predictions are.\n",
        "\n",
        "* **Mean Absolute Error (MAE)** is calculated using torch.abs to compute the absolute differences between true and predicted values, then averaging them using torch.mean.\n",
        "* **Mean Squared Error (MSE)** is computed by squaring the differences and averaging them, using torch.mean as well.\n",
        "* **R-squared (R²)** is calculated by:\n",
        "  * R² = `1 - ss_residual / ss_total`.\n",
        "  * `ss_total`: the total sum of squares (variance of the true values).\n",
        "  * `ss_residual`: the residual sum of squares (difference between true and predicted values)."
      ],
      "metadata": {
        "id": "aNzmgppfJEnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute evaluation metrics\n",
        "def evaluate_metrics(true_values, predicted_values):\n",
        "    # Convert to tensors if they're not already\n",
        "    true_values = true_values.float()\n",
        "    predicted_values = predicted_values.float()\n",
        "\n",
        "    # Mean Absolute Error (MAE)\n",
        "    mae = XXXX\n",
        "\n",
        "    # Mean Squared Error (MSE)\n",
        "    mse = XXXX\n",
        "\n",
        "    # R-squared (R²)\n",
        "    ss_total = XXXX\n",
        "    ss_residual = XXXX\n",
        "    r2 = 1 - XXXX\n",
        "\n",
        "    return mae.item(), mse.item(), r2.item()"
      ],
      "metadata": {
        "id": "QK5uUXBeIwnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the actual values and the predicted values as PyTorch tensors\n",
        "actual_values = torch.tensor(actuals, dtype=torch.float32)\n",
        "predicted_values = torch.tensor(predictions, dtype=torch.float32)\n",
        "\n",
        "# Evaluate the model\n",
        "mae, mse, r2 = XXXX\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"R-squared (R²): {r2:.4f}\")"
      ],
      "metadata": {
        "id": "jpwi3BIRIyxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's plot the data to see how it looks."
      ],
      "metadata": {
        "id": "vr1yD6UlJJ3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predicted vs actual values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(actuals, label='Actual', color='blue')\n",
        "plt.plot(predictions, label='Predicted', color='red', linestyle='--')\n",
        "plt.xlabel('Time Step')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-2POic1ZI0LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmmm, I think we can do better!"
      ],
      "metadata": {
        "id": "7l6lHD7tJMzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Challenge Time!\n",
        "\n",
        "Now that we’ve successfully implemented and evaluated the transformer model, it’s time for a challenge. Below are several areas where you can explore improvements, but feel free to try your own ideas too!\n",
        "\n",
        "**1. Hyperparameter Tuning:**\n",
        "  * Increase the number of layers in the transformer model. This can help capture more complex relationships in the data.\n",
        "  * Adjust the number of attention heads (`nhead`). Try increasing or decreasing it to see how it affects performance.\n",
        "  * Change the model dimension (`d_model`) and the size of the feedforward layer (`dim_feedforward`). Larger values might allow the model to capture more complex patterns, but they also increase the risk of overfitting.\n",
        "\n",
        "**2. Sequence Length:**\n",
        "  * Try increasing the sequence length (`seq_length`). A longer history might help the model predict more accurately, but it also increases the computational cost.\n",
        "  * Alternatively, decrease the sequence length to see if the model performs better with less data.\n",
        "\n",
        "**3. Learning Rate:**\n",
        "  * Experiment with different learning rates to optimize the training process. You can try smaller learning rates like 1e-6 or larger ones like 1e-3 to see how it affects convergence.\n",
        "\n",
        "**4. Optimizer:**\n",
        "  * Try using other optimizers like SGD or RMSprop to see if they perform better for this problem.\n",
        "\n",
        "**5. Data Augmentation:**\n",
        "  * If your data allows it, try applying data augmentation techniques such as noise addition, time warping, or random scaling to make the model more robust.\n",
        "\n",
        "**6. Early Stopping:**\n",
        "  * Implement early stopping to prevent overfitting. If the model’s performance stops improving after a certain number of epochs, halt training early.\n",
        "\n",
        "**7. Regularization:**\n",
        "  * Try increasing the dropout rate in the transformer layers to help prevent overfitting.\n",
        "  * Experiment with L2 regularization (weight decay) to penalize large model weights.\n",
        "\n",
        "**8. Loss Function:**\n",
        "  * You are using MSELoss as the loss function.Experiment with other loss functions like Huber Loss (less sensitive to outliers) or Log-Cosh Loss (smooths out large errors).\n",
        "\n",
        "**9. Model Architecture:**\n",
        "  * Consider adding additional components to the transformer model. For example, you could introduce a multi-scale approach, where the model predicts at different time scales and combines them for the final prediction.\n",
        "\n",
        "**Challenge Task:**\n",
        "* Try different hyperparameters and see if you can achieve better results on the test set.\n",
        "* Visualize how your changes affect the training and testing loss. Plot the metrics after implementing each modification and compare the model performance.\n",
        "* Evaluate the final model using the evaluation metrics (MAE, MSE, R²), and discuss the trade-offs between overfitting and underfitting as you experiment with different strategies.\n",
        "* Track your experiments with tools like MLFlow or TensorBoard to monitor the training process and compare results from different model configurations.\n",
        "\n",
        "Good luck! Have fun experimenting with the model and share what improvements you find!"
      ],
      "metadata": {
        "id": "EL3Rxyy6JPi7"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11 (torch)",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}