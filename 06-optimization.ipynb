{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a0154b4",
      "metadata": {
        "id": "9a0154b4"
      },
      "source": [
        "# Lab 6: Optimization Methods in PyTorch\n",
        "\n",
        "The goal of this lab is to improve the performance of a deep learning model by implementing various regularization and normalization techniques in PyTorch.\n",
        "\n",
        "**What You'll Do:**\n",
        "- Apply **L1/L2 weight decay**.\n",
        "- Implement **Dropout**.\n",
        "- Implement **Normalization (BatchNorm, LayerNorm, etc.)**.\n",
        "- Use **Early Stopping**.\n",
        "- Experiment with **Data Augmentation (CutMix, Mixup)**.\n",
        "\n",
        "You'll be given challenges where you must use the **PyTorch documentation** to complete missing parts!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Imports"
      ],
      "metadata": {
        "id": "_NDtx4jouESj"
      },
      "id": "_NDtx4jouESj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a86b48",
      "metadata": {
        "id": "24a86b48"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(24)  # For reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5211f047",
      "metadata": {
        "id": "5211f047"
      },
      "source": [
        "## Part 2: Load the Dataset\n",
        "We'll use CIFAR-10, a small image classification dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808d41a5",
      "metadata": {
        "id": "808d41a5"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b42e443",
      "metadata": {
        "id": "5b42e443"
      },
      "source": [
        "## Part 3. Define a Simple CNN\n",
        "We'll start with a basic CNN model and optimize it throughout the challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4294419",
      "metadata": {
        "id": "e4294419"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        XXXX\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = XXXX\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = XXXX\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd20689",
      "metadata": {
        "id": "fdd20689"
      },
      "source": [
        "## Part 5: Apply L2 Regularization (Weight Decay)\n",
        "Modify the optimizer to use **L2 regularization**. Check out the PyTorch documentation for the Adam optimizer [here](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14719b44",
      "metadata": {
        "id": "14719b44"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3f0341c",
      "metadata": {
        "id": "b3f0341c"
      },
      "source": [
        "## Part 6: Add Dropout to the Model\n",
        "Modify the **SimpleCNN** class you created above to include **Dropout layers**. Check out the documentation on dropout layers [here](https://pytorch.org/docs/stable/nn.html#dropout-layers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4507ef20",
      "metadata": {
        "id": "4507ef20"
      },
      "outputs": [],
      "source": [
        "class DropoutCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DropoutCNN, self).__init__()\n",
        "        XXXX\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = XXXX\n",
        "        x = XXXX\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = XXXX\n",
        "        return x\n",
        "\n",
        "model = DropoutCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7659075a",
      "metadata": {
        "id": "7659075a"
      },
      "source": [
        "## Part 7: Add Batch Normalization\n",
        "Modify the CNN to include **BatchNorm** after each convolutional layer.\n",
        "\n",
        "**Extra challenge**: Try to find the documentation for this on your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e0b952",
      "metadata": {
        "id": "91e0b952"
      },
      "outputs": [],
      "source": [
        "class BatchNormCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BatchNormCNN, self).__init__()\n",
        "        XXXX\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = XXXX\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = XXXX\n",
        "        return x\n",
        "\n",
        "model = BatchNormCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b80e7cf",
      "metadata": {
        "id": "9b80e7cf"
      },
      "source": [
        "## Part 8: Implement Early Stopping\n",
        "**Challenge 1**: Write the training code into the loop\n",
        "\n",
        "**Challenge 2**: Modify the loop to stop if validation loss doesn't improve after **N epochs**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "869965f4",
      "metadata": {
        "id": "869965f4"
      },
      "outputs": [],
      "source": [
        "best_loss = float('inf')\n",
        "patience = 5  # Training stops after this many epochs with no improvement\n",
        "counter = 0  # Count the consecutive epochs without improvement\n",
        "\n",
        "for epoch in range(50):\n",
        "\n",
        "    # Insert model training code here\n",
        "\n",
        "    val_loss = XXXX  # compute validation loss\n",
        "\n",
        "    if XXXX:\n",
        "        XXXX = XXXX  # update 'best_loss'\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if XXXX:\n",
        "            XXXX  # stop training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 9: Data Augmentation\n",
        "\n",
        "**Here's the big challenge for today**: Implement both ***CutMix*** and ***MixUp*** to your data!\n",
        "\n",
        "1.   Augment your data with both CutMix and MixUp. In other words, randomly select images and apply one or the other method. Do not apply both methods to the same image.\n",
        "2.   Use your new augmented data to train a simple CNN with Dropout, BatchNorm, and Early Stopping.\n",
        "\n"
      ],
      "metadata": {
        "id": "f5yYf9z1yD1Z"
      },
      "id": "f5yYf9z1yD1Z"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}